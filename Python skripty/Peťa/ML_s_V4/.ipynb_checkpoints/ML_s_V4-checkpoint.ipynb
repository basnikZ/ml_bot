{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4291d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 9s 416ms/step - loss: 0.0916 - rmse: 0.3026 - val_loss: 0.0259 - val_rmse: 0.1611\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0163 - rmse: 0.1275 - val_loss: 0.0069 - val_rmse: 0.0833\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 3s 276ms/step - loss: 0.0083 - rmse: 0.0910 - val_loss: 0.0086 - val_rmse: 0.0925\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.0063 - rmse: 0.0795 - val_loss: 0.0045 - val_rmse: 0.0668\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 3s 272ms/step - loss: 0.0053 - rmse: 0.0726 - val_loss: 0.0050 - val_rmse: 0.0707\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.0055 - rmse: 0.0743 - val_loss: 0.0046 - val_rmse: 0.0681\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 0.0047 - rmse: 0.0682 - val_loss: 0.0041 - val_rmse: 0.0643\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.0047 - rmse: 0.0688 - val_loss: 0.0038 - val_rmse: 0.0613\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0048 - rmse: 0.0696 - val_loss: 0.0043 - val_rmse: 0.0653\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0044 - rmse: 0.0666 - val_loss: 0.0034 - val_rmse: 0.0581\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0044 - rmse: 0.0664 - val_loss: 0.0033 - val_rmse: 0.0573\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0045 - rmse: 0.0670 - val_loss: 0.0035 - val_rmse: 0.0587\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0043 - rmse: 0.0658 - val_loss: 0.0033 - val_rmse: 0.0574\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.0047 - rmse: 0.0687 - val_loss: 0.0038 - val_rmse: 0.0616\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.0043 - rmse: 0.0658 - val_loss: 0.0031 - val_rmse: 0.0556\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 3s 282ms/step - loss: 0.0038 - rmse: 0.0619 - val_loss: 0.0040 - val_rmse: 0.0633\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.0041 - rmse: 0.0642 - val_loss: 0.0042 - val_rmse: 0.0650\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0050 - rmse: 0.0704 - val_loss: 0.0038 - val_rmse: 0.0620\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.0041 - rmse: 0.0640 - val_loss: 0.0035 - val_rmse: 0.0594\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.0038 - rmse: 0.0613 - val_loss: 0.0027 - val_rmse: 0.0521\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0036 - rmse: 0.0597 - val_loss: 0.0027 - val_rmse: 0.0523\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0037 - rmse: 0.0611 - val_loss: 0.0042 - val_rmse: 0.0644\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.0036 - rmse: 0.0602 - val_loss: 0.0028 - val_rmse: 0.0527\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.0035 - rmse: 0.0594 - val_loss: 0.0026 - val_rmse: 0.0506\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.0036 - rmse: 0.0598 - val_loss: 0.0026 - val_rmse: 0.0509\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.0036 - rmse: 0.0599 - val_loss: 0.0023 - val_rmse: 0.0484\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.0035 - rmse: 0.0591 - val_loss: 0.0036 - val_rmse: 0.0596\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0044 - rmse: 0.0666 - val_loss: 0.0026 - val_rmse: 0.0506\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0037 - rmse: 0.0606 - val_loss: 0.0024 - val_rmse: 0.0487\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.0044 - rmse: 0.0661 - val_loss: 0.0024 - val_rmse: 0.0492\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0042 - rmse: 0.0651 - val_loss: 0.0025 - val_rmse: 0.0497\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0037 - rmse: 0.0612 - val_loss: 0.0025 - val_rmse: 0.0498\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.0038 - rmse: 0.0618 - val_loss: 0.0023 - val_rmse: 0.0480\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.0037 - rmse: 0.0610 - val_loss: 0.0027 - val_rmse: 0.0522\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0035 - rmse: 0.0594 - val_loss: 0.0025 - val_rmse: 0.0498\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.0033 - rmse: 0.0575 - val_loss: 0.0022 - val_rmse: 0.0465\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.0034 - rmse: 0.0584 - val_loss: 0.0022 - val_rmse: 0.0464\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.0036 - rmse: 0.0596 - val_loss: 0.0022 - val_rmse: 0.0466\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0037 - rmse: 0.0609 - val_loss: 0.0022 - val_rmse: 0.0471\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.0035 - rmse: 0.0590 - val_loss: 0.0023 - val_rmse: 0.0481\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0041 - rmse: 0.0644 - val_loss: 0.0022 - val_rmse: 0.0470\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0033 - rmse: 0.0576 - val_loss: 0.0022 - val_rmse: 0.0465\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.0034 - rmse: 0.0582 - val_loss: 0.0022 - val_rmse: 0.0466\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0035 - rmse: 0.0591 - val_loss: 0.0026 - val_rmse: 0.0510\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0040 - rmse: 0.0631 - val_loss: 0.0021 - val_rmse: 0.0454\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.0044 - rmse: 0.0661 - val_loss: 0.0023 - val_rmse: 0.0476\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0039 - rmse: 0.0628 - val_loss: 0.0026 - val_rmse: 0.0511\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.0032 - rmse: 0.0569 - val_loss: 0.0040 - val_rmse: 0.0629\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0034 - rmse: 0.0585 - val_loss: 0.0035 - val_rmse: 0.0588\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.0034 - rmse: 0.0585 - val_loss: 0.0028 - val_rmse: 0.0530\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0035 - rmse: 0.0587 - val_loss: 0.0024 - val_rmse: 0.0489\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.0031 - rmse: 0.0556 - val_loss: 0.0021 - val_rmse: 0.0457\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.0030 - rmse: 0.0543 - val_loss: 0.0020 - val_rmse: 0.0447\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.0035 - rmse: 0.0590 - val_loss: 0.0020 - val_rmse: 0.0442\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0036 - rmse: 0.0601 - val_loss: 0.0019 - val_rmse: 0.0439\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.0031 - rmse: 0.0558 - val_loss: 0.0036 - val_rmse: 0.0600\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.0036 - rmse: 0.0602 - val_loss: 0.0030 - val_rmse: 0.0545\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0041 - rmse: 0.0638 - val_loss: 0.0029 - val_rmse: 0.0542\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.0037 - rmse: 0.0605 - val_loss: 0.0020 - val_rmse: 0.0443\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.0039 - rmse: 0.0622 - val_loss: 0.0019 - val_rmse: 0.0440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.0032 - rmse: 0.0570 - val_loss: 0.0025 - val_rmse: 0.0501\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.0047 - rmse: 0.0687 - val_loss: 0.0026 - val_rmse: 0.0506\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.0040 - rmse: 0.0631 - val_loss: 0.0019 - val_rmse: 0.0431\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 3s 294ms/step - loss: 0.0030 - rmse: 0.0547 - val_loss: 0.0022 - val_rmse: 0.0471\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0027 - rmse: 0.0517 - val_loss: 0.0024 - val_rmse: 0.0493\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0034 - rmse: 0.0582 - val_loss: 0.0026 - val_rmse: 0.0508\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.0031 - rmse: 0.0560 - val_loss: 0.0021 - val_rmse: 0.0453\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.0029 - rmse: 0.0537 - val_loss: 0.0019 - val_rmse: 0.0431\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0033 - rmse: 0.0572 - val_loss: 0.0020 - val_rmse: 0.0452\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0033 - rmse: 0.0571 - val_loss: 0.0026 - val_rmse: 0.0508\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.0028 - rmse: 0.0526 - val_loss: 0.0022 - val_rmse: 0.0472\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.0028 - rmse: 0.0533 - val_loss: 0.0023 - val_rmse: 0.0483\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0032 - rmse: 0.0566 - val_loss: 0.0021 - val_rmse: 0.0461\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.0028 - rmse: 0.0525 - val_loss: 0.0022 - val_rmse: 0.0469\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.0031 - rmse: 0.0554 - val_loss: 0.0038 - val_rmse: 0.0619\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.0036 - rmse: 0.0602 - val_loss: 0.0023 - val_rmse: 0.0479\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0029 - rmse: 0.0535 - val_loss: 0.0017 - val_rmse: 0.0417\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0030 - rmse: 0.0549 - val_loss: 0.0018 - val_rmse: 0.0425\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0030 - rmse: 0.0546 - val_loss: 0.0017 - val_rmse: 0.0414\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0031 - rmse: 0.0558 - val_loss: 0.0022 - val_rmse: 0.0470\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0028 - rmse: 0.0528 - val_loss: 0.0024 - val_rmse: 0.0492\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.0032 - rmse: 0.0564 - val_loss: 0.0020 - val_rmse: 0.0452\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0034 - rmse: 0.0583 - val_loss: 0.0016 - val_rmse: 0.0404\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0032 - rmse: 0.0562 - val_loss: 0.0017 - val_rmse: 0.0410\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0030 - rmse: 0.0550 - val_loss: 0.0027 - val_rmse: 0.0515\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.0028 - rmse: 0.0531 - val_loss: 0.0021 - val_rmse: 0.0459\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0027 - rmse: 0.0521 - val_loss: 0.0018 - val_rmse: 0.0428\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0030 - rmse: 0.0552 - val_loss: 0.0017 - val_rmse: 0.0409\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0032 - rmse: 0.0564 - val_loss: 0.0018 - val_rmse: 0.0424\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.0026 - rmse: 0.0511 - val_loss: 0.0020 - val_rmse: 0.0449\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0022 - rmse: 0.0472 - val_loss: 0.0026 - val_rmse: 0.0508\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.0030 - rmse: 0.0547 - val_loss: 0.0040 - val_rmse: 0.0630\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.0030 - rmse: 0.0552 - val_loss: 0.0021 - val_rmse: 0.0461\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0037 - rmse: 0.0609 - val_loss: 0.0018 - val_rmse: 0.0424\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0034 - rmse: 0.0585 - val_loss: 0.0020 - val_rmse: 0.0447\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0037 - rmse: 0.0611 - val_loss: 0.0024 - val_rmse: 0.0495\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.0034 - rmse: 0.0581 - val_loss: 0.0018 - val_rmse: 0.0421\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0031 - rmse: 0.0557 - val_loss: 0.0020 - val_rmse: 0.0445\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.0034 - rmse: 0.0587 - val_loss: 0.0018 - val_rmse: 0.0422\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.0032 - rmse: 0.0561 - val_loss: 0.0026 - val_rmse: 0.0510\n",
      "3/3 [==============================] - 1s 37ms/step\n",
      "Actual price: 149.71 - Predicted price: 145.05\n",
      "Actual price: 151.12 - Predicted price: 144.24\n",
      "Actual price: 146.55 - Predicted price: 140.55\n",
      "Actual price: 137.09 - Predicted price: 126.84\n",
      "Actual price: 106.84 - Predicted price: 114.43\n",
      "Actual price: 119.49 - Predicted price: 109.73\n",
      "Actual price: 151.28 - Predicted price: 148.06\n",
      "Actual price: 116.60 - Predicted price: 116.43\n",
      "Actual price: 175.74 - Predicted price: 163.15\n",
      "Actual price: 134.99 - Predicted price: 133.11\n",
      "Actual price: 164.77 - Predicted price: 156.15\n",
      "Actual price: 131.46 - Predicted price: 131.55\n",
      "Actual price: 115.56 - Predicted price: 112.25\n",
      "Actual price: 118.69 - Predicted price: 112.46\n",
      "Actual price: 174.33 - Predicted price: 163.80\n",
      "Actual price: 142.83 - Predicted price: 143.23\n",
      "Actual price: 148.85 - Predicted price: 143.68\n",
      "Actual price: 123.24 - Predicted price: 117.53\n",
      "Actual price: 143.29 - Predicted price: 142.24\n",
      "Actual price: 122.94 - Predicted price: 114.73\n",
      "Actual price: 92.85 - Predicted price: 98.36\n",
      "Actual price: 139.07 - Predicted price: 126.57\n",
      "Actual price: 119.98 - Predicted price: 123.46\n",
      "Actual price: 91.03 - Predicted price: 93.57\n",
      "Actual price: 115.98 - Predicted price: 113.23\n",
      "Actual price: 130.36 - Predicted price: 121.18\n",
      "Actual price: 113.90 - Predicted price: 98.18\n",
      "Actual price: 171.18 - Predicted price: 159.91\n",
      "Actual price: 97.72 - Predicted price: 95.22\n",
      "Actual price: 127.88 - Predicted price: 120.22\n",
      "Actual price: 133.41 - Predicted price: 131.53\n",
      "Actual price: 136.87 - Predicted price: 126.39\n",
      "Actual price: 142.81 - Predicted price: 141.25\n",
      "Actual price: 129.04 - Predicted price: 117.37\n",
      "Actual price: 116.87 - Predicted price: 115.99\n",
      "Actual price: 126.52 - Predicted price: 114.70\n",
      "Actual price: 120.96 - Predicted price: 121.78\n",
      "Actual price: 180.33 - Predicted price: 177.40\n",
      "Actual price: 116.59 - Predicted price: 116.69\n",
      "Actual price: 136.69 - Predicted price: 124.23\n",
      "Actual price: 125.89 - Predicted price: 127.75\n",
      "Actual price: 108.94 - Predicted price: 98.27\n",
      "Actual price: 114.91 - Predicted price: 110.21\n",
      "Actual price: 121.19 - Predicted price: 112.94\n",
      "Actual price: 126.11 - Predicted price: 126.86\n",
      "Actual price: 117.51 - Predicted price: 115.00\n",
      "Actual price: 115.01 - Predicted price: 108.04\n",
      "Actual price: 110.08 - Predicted price: 112.59\n",
      "Actual price: 161.84 - Predicted price: 159.54\n",
      "Actual price: 111.81 - Predicted price: 111.77\n",
      "Actual price: 128.70 - Predicted price: 121.08\n",
      "Actual price: 165.32 - Predicted price: 159.47\n",
      "Actual price: 146.92 - Predicted price: 146.98\n",
      "Actual price: 147.54 - Predicted price: 146.58\n",
      "Actual price: 95.75 - Predicted price: 94.28\n",
      "Actual price: 121.09 - Predicted price: 123.42\n",
      "Actual price: 120.88 - Predicted price: 121.25\n",
      "Actual price: 150.96 - Predicted price: 147.18\n",
      "Actual price: 121.10 - Predicted price: 113.31\n",
      "Actual price: 122.41 - Predicted price: 118.66\n",
      "Actual price: 148.99 - Predicted price: 145.32\n",
      "Actual price: 125.57 - Predicted price: 120.11\n",
      "Actual price: 153.49 - Predicted price: 149.45\n",
      "Actual price: 130.48 - Predicted price: 126.84\n",
      "Actual price: 127.90 - Predicted price: 121.28\n",
      "Actual price: 93.17 - Predicted price: 93.98\n",
      "Actual price: 133.11 - Predicted price: 132.33\n",
      "Actual price: 115.32 - Predicted price: 115.46\n",
      "Actual price: 126.85 - Predicted price: 126.03\n",
      "Actual price: 125.35 - Predicted price: 133.19\n",
      "Actual price: 115.81 - Predicted price: 108.54\n",
      "Actual price: 134.78 - Predicted price: 132.62\n",
      "Actual price: 122.54 - Predicted price: 120.68\n",
      "Actual price: 139.14 - Predicted price: 143.44\n",
      "Actual price: 123.75 - Predicted price: 114.34\n",
      "Actual price: 148.64 - Predicted price: 141.56\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "\n",
    "def load_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_data(data, lookback, days_ahead):\n",
    "    data = data[['Close']]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(lookback, len(data) - days_ahead):\n",
    "        X.append(scaled_data[i - lookback:i, 0])\n",
    "        y.append(scaled_data[i + days_ahead, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "ticker = 'AAPL'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2021-12-31'\n",
    "lookback = 120\n",
    "days_ahead = 5\n",
    "\n",
    "# Load historical stock data\n",
    "data = load_data(ticker, start_date, end_date)\n",
    "\n",
    "# Preprocess the data\n",
    "X, y, scaler = preprocess_data(data, lookback, days_ahead)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], 1))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(units=100)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Custom metric: Root Mean Squared Error\n",
    "rmse = RootMeanSquaredError(name='rmse')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[rmse])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Calculate the inverse transform of 'y_test'\n",
    "actual_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Print the actual stock prices and their corresponding predictions\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Actual price: {actual_prices[i][0]:.2f} - Predicted price: {predictions[i][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5863746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
